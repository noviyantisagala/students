{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04dfc425",
   "metadata": {},
   "source": [
    "# PBT57057 - Smart Academic Advisory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7064705e",
   "metadata": {},
   "source": [
    "We used SOCS student dataset (kemanggisan & alam sutera) since 2010 - 2021 (odd term only). Most features of dataset is presented as categorical type.    \n",
    "     \n",
    "**The goal is to try to build 'the best' possible classification model which can be used to predict who will belong to NR. It is expected to help SASC team in the future by getting information earlier.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce7f82",
   "metadata": {},
   "source": [
    "### Description of Dataset Mahasiswa   \n",
    "    \n",
    "`Status` = Status mahasiswa (Lulus, Belum Lulus, Dismissal', 'Aktif', 'Cuti)   \n",
    "`NIM`    = Nomor Induk Mahasiswa   \n",
    "`Name`   = Nama Mahasiswa   \n",
    "`IntOrg` = Status keikutsertaan internal organisasi (N = tidak bergabung; Y = bergabung)    \n",
    "`ExtOrg` = Status keikutsertaan external organisasi (N = tidak bergabung; Y = bergabung)    \n",
    "`PartInAcadComp` = Status keikutsertaan dalam kompetisi akademik ( N = tidak pernah; Y = pernah)  \n",
    "`Term` = Semester (1420 --> Binusian 14 semester genap; 1410--> Binusian 14 semester ganjil)      \n",
    "    \n",
    "       \n",
    "### Description of Data Demografi   \n",
    "`Term`  = Semester   \n",
    "`nofom` = Nomor formulir saat pendaftaran   \n",
    "`NIM`   = Nomor Induk Mahasiswa   \n",
    "`Name`  = Nama mahasiswa    \n",
    "`BinusianID` = Binusian ID   \n",
    "`acad_group` = academic group (S0CS)    \n",
    "`Status` = Status Mahasiswa (Undur Diri', 'Lulus', 'Dismissal', 'Aktif', 'Cuti)    \n",
    "`Age`  = Usia Mahasiswa (dihitung dari tgl lahir hingga 2022)    \n",
    "`Gender` = Gender     \n",
    "`ScholarshipStatus` = Jenis Beasiswa yang diterima    \n",
    "`English Score` = Nilai tes TOEFL PBT BINUS    \n",
    "`RangeSalaryFa` = Gaji Ayah dalam bentuk range (4 kategori yaitu < 10jt; 10jt-19,99jt; 20jt - 29,99jt; >=30jt)   \n",
    "`SalaryFa` = Gaji Ayah (6 kategori yaitu 3jt, 5jt, 10jt, 15jt, 20jt, 30jt)   \n",
    "`TuitionLevel` = Biaya kuliah yang dibebankan ke mahasiswa   \n",
    "`Address` = alamat mahasiswa    \n",
    "`FaJob` = Pekerjaan Ayah (Pegawai negeri sipil; Pegawai swasta; Wiraswasta; ABRI; Tidak bekerja; Pensiun; Guru; Lain - Lain; PTS (Perguruan Tinggi Swasta)'; 'PTN (Perguruan Tinggi Negeri)';'Petani)         \n",
    "   \n",
    "`MoJob` = Pekerjaan Ibu (Pegawai negeri sipil; Pegawai swasta; Wiraswasta; ABRI; Tidak bekerja;  Pensiun; Guru; Lain - Lain; PTS (Perguruan Tinggi Swasta)'; 'PTN (Perguruan Tinggi Negeri)';'Petani)        \n",
    "     \n",
    "`EducationFa` = Pendidikan terakhir ayah ( MASTER; Sarjana; DOCTOR; Tamat SLTA; DIPLOMA (D3); Diploma(D4); Diploma(D2); Diploma(D1); Tamat SMP, Tamat SD; Specialist 1; Tidak Tamat SD; Specialist 2; High School (SMA))       \n",
    "   \n",
    "    \n",
    "`EducationMo` = Pendidikan terakhir Ibu ( MASTER; Sarjana; DOCTOR; Tamat SLTA; DIPLOMA (D3);    Diploma(D4); Diploma(D2); Diploma(D1); Tamat SMP, Tamat SD; Specialist 1; Tidak Tamat SD; Specialist 2; High School (SMA))       \n",
    "   \n",
    "`StatusFa` = Status ayah( Masih Hidup; Telah meninggal)    \n",
    "`StatusMo` = Status Ibu( Masih Hidup; Telah Meninggal)    \n",
    "`fixed`    = variabel yang dipakai untuk menarik data    \n",
    "`variable` = variabel yang dipakai untuk menarik data      \n",
    "   \n",
    "### Description of Dataset Prestasi Mahasiswa   \n",
    "   \n",
    "`Term`   = Semester   \n",
    "`NIM`     = Nomor Induk Mahasiswa   \n",
    "`Jurusan/Program` = Program Studi/Program   \n",
    "`KategoriJurusan` = Kategori Jurusan (Ganda; reguler)   \n",
    "`LokasiKuliah` = Lokasi Kuliah (Kemanggisan; Alam Sutera)   \n",
    "`Angkatan`  = Angkatan mahasiswa (2000 - 2020)   \n",
    "`PeriodeMasuk` = Semester   \n",
    "`Semesterke` = Semester berjalan   \n",
    "`SKSLulusSemesterBerjalan` = Total SKS yang sudah diambil mahasiswa     \n",
    "`StatusIPK` = Status IPK Mahasiswa (IPK Kurang = dibawah 2.00; OK= >=2.00)     \n",
    "`StatusSKS` = Stauts SKS mahasiswa (SKS Kurang = SKS kumulatif kurang dari kelipatan 15 sks per semester/lebih dari 10 semester; OK )     \n",
    "`Evaluasi` = Evaluasi prestasi akademik mahasiswa (NR; Middle--> IPK 2.00 - 2.99; High--> 3.00 - 4.00)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07afc6cc",
   "metadata": {},
   "source": [
    "### **LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af52bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "import pydotplus\n",
    "import math\n",
    "import pickle \n",
    "\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import Pool\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import export_text\n",
    "from six import StringIO\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from IPython.display import Image  \n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c87f30d",
   "metadata": {},
   "source": [
    "### **READ DATA** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce2b3fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data mahasiswa\n",
    "data = pd.read_excel (r'datamahasiswa.xlsx') \n",
    "\n",
    "#Read data demografi mahasiswa\n",
    "data_demo = pd.read_excel (r'DemografiMahasiswa.xlsx') \n",
    "\n",
    "#Read data prestasi mahasiswa\n",
    "data_prestasi = pd.read_excel (r'timsasc.xlsx') \n",
    "\n",
    "df_copy = pd.DataFrame(data)\n",
    "df_demo_copy = pd.DataFrame(data_demo)\n",
    "df_pres_copy = pd.DataFrame(data_prestasi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de729c7",
   "metadata": {},
   "source": [
    "## Make a copy of the data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a172f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_copy\n",
    "df_demo = df_demo_copy\n",
    "df_pres = df_pres_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e27c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['BinusianID', 'Name', 'Status'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1dd22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c883df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "removal_list = [1330,1430,1530,1630,1730,1830,1930,2030]\n",
    "\n",
    "df = df[~df['Term'].isin(removal_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff48df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values from term attribute\n",
    "df = df.dropna(subset=['Term'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6a1e03",
   "metadata": {},
   "source": [
    "***Final data mahasiswa used is 32223 rows, 6 columns***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a915ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert type of variables for merging reason\n",
    "df['Term']=df['Term'].astype('Int64')\n",
    "df['NIM']=df['NIM'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb5f2b",
   "metadata": {},
   "source": [
    "#### **Remove Unimportant Features** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55d69354",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = df_demo.drop(['nofom', 'acad_Career', 'Name', 'BinusianID','acad_group', 'Age', 'RangeSalaryFa', 'RangeSalaryMo','SalaryMo','SalaryFa','TuitionLevel','Address', 'fixed', 'variable'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13987725",
   "metadata": {},
   "source": [
    "### Remove duplicate values and short term values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fd0d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = df_demo.replace('-', np.nan)\n",
    "\n",
    "#remove rows with short term (xx30)\n",
    "df_demo = df_demo.drop(df_demo[df_demo.Term.isin([1330,1430,1530,1630,1730,1830,1930,2030,2120])].index)\n",
    "\n",
    "#remove duplicate rows\n",
    "df_demo = df_demo.drop_duplicates(subset = ['NIM','Term'],\n",
    "                     keep = 'first').reset_index(drop=True)\n",
    "\n",
    "#remove NA from Term attribute\n",
    "df_demo = df_demo.dropna(subset=['Term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "166d0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert term type for merging reason\n",
    "df_demo['Term']=df_demo['Term'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c39049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename values\n",
    "df_pres.loc[df_pres[\"JurusanOrProgram\"] == \"Computer Science\", \"JurusanOrProgram\"] = 'A'\n",
    "df_pres.loc[df_pres[\"JurusanOrProgram\"] == \"Computer Science & Mathematics\", \"JurusanOrProgram\"] = 'B'\n",
    "df_pres.loc[df_pres[\"JurusanOrProgram\"] == \"Computer Science & Statistics\", \"JurusanOrProgram\"] = 'C'\n",
    "df_pres.loc[df_pres[\"JurusanOrProgram\"] == \"Mobile Application & Technology\", \"JurusanOrProgram\"] = 'D'\n",
    "df_pres.loc[df_pres[\"JurusanOrProgram\"] == \"Game Application & Technology\", \"JurusanOrProgram\"] = 'E'\n",
    "df_pres.loc[df_pres[\"JurusanOrProgram\"] == \"Computer Science - Global Class\", \"JurusanOrProgram\"] = 'F'\n",
    "df_pres.loc[df_pres[\"JurusanOrProgram\"] == \"Master of Information Technology - Master Track\", \"JurusanOrProgram\"] = 'H'\n",
    "df_pres.loc[df_pres[\"JurusanOrProgram\"] == \"Cyber Security\", \"JurusanOrProgram\"] = 'G'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00d967",
   "metadata": {},
   "source": [
    "#### MERGE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cae218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a left join—also known as a left outer join—with the how parameter. \n",
    "#Using a left outer join will leave your new merged DataFrame with all rows from the left DataFrame, \n",
    "#while discarding rows from the right DataFrame that don’t have a match in the key column of the left DataFrame.\n",
    "\n",
    "finalDF = pd.merge(df_demo,df, on=[\"Term\", \"NIM\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32d71589",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF = pd.merge(finalDF,df_pres, on=[\"Term\", \"NIM\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "188e5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove NA from Term attribute\n",
    "finalDF.dropna(subset=['Evaluasi'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e89665",
   "metadata": {},
   "source": [
    "### take only 'angkatan' >= 2010 and Semester 1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "078f966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDFF=finalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cce149d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = finalDF[finalDF['SemesterKe'].isin([3,4,5])][['NIM','SemesterKe']]\n",
    "\n",
    "finalDFF = finalDFF[finalDFF['SemesterKe'].isin([1,2,3,4,5])][['NIM','SemesterKe']]\n",
    "df1g = finalDFF.groupby(['NIM']).count()\n",
    "df1g = df1g.reset_index()\n",
    "#check data student yg ada semester 3- semester 6\n",
    "df1g = df1g[df1g['SemesterKe']==5]\n",
    "#make a list of NIM\n",
    "index_NIM = list(df1g['NIM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2cffa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To select rows whose column value is in an iterable array, which we'll define as array, you can use isin:\n",
    "df = finalDF.loc[(finalDF['NIM'].isin(index_NIM)) & finalDF['SemesterKe'].isin([1,2,3,4,5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01fd70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel('finaldataset.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3013d8ac",
   "metadata": {},
   "source": [
    "## Set Label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd47acc",
   "metadata": {},
   "source": [
    "**Middle and High ar set as 0(nonNR) while Non Reguler as 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e578282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the condition\n",
    "df.loc[df[\"Evaluasi\"] == \"Non Reguler\", \"Evaluasi\"] = 1\n",
    "df.loc[df[\"Evaluasi\"] == \"Middle\", \"Evaluasi\"] = 0\n",
    "df.loc[df[\"Evaluasi\"] == \"High\", \"Evaluasi\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6200eb93",
   "metadata": {},
   "source": [
    "### Convert English Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "733b0849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NOVIYA~1.SAG\\AppData\\Local\\Temp/ipykernel_25288/1074542399.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['EnglishScore'] = np.where(df['EnglishScore'] > '550', 'Advance', df['EnglishScore'])\n",
      "C:\\Users\\NOVIYA~1.SAG\\AppData\\Local\\Temp/ipykernel_25288/1074542399.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['EnglishScore'] = np.where((df['EnglishScore'] <= '550') & (df['EnglishScore'] >= '467'), \"Intermediate\", df['EnglishScore'])\n",
      "C:\\Users\\NOVIYA~1.SAG\\AppData\\Local\\Temp/ipykernel_25288/1074542399.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['EnglishScore'] = np.where(df['EnglishScore'] < '467', 'Beginner', df['EnglishScore'])\n"
     ]
    }
   ],
   "source": [
    "#Replace englishscore with englishLevel\n",
    "df['EnglishScore'] = np.where(df['EnglishScore'] > '550', 'Advance', df['EnglishScore'])\n",
    "df['EnglishScore'] = np.where((df['EnglishScore'] <= '550') & (df['EnglishScore'] >= '467'), \"Intermediate\", df['EnglishScore'])\n",
    "df['EnglishScore'] = np.where(df['EnglishScore'] < '467', 'Beginner', df['EnglishScore'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1e7330",
   "metadata": {},
   "source": [
    "## REMOVE UNNECESSARY STRIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b9dcea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NOVIYA~1.SAG\\AppData\\Local\\Temp/ipykernel_25288/4115642951.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['EducationFa'] = df['EducationFa'].str.replace(\" \",\"\")\n",
      "C:\\Users\\NOVIYA~1.SAG\\AppData\\Local\\Temp/ipykernel_25288/4115642951.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['EducationMo'] = df['EducationMo'].str.replace(\" \",\"\")\n"
     ]
    }
   ],
   "source": [
    "'''strip leading and trailing space'''\n",
    " \n",
    "df['EducationFa'] = df['EducationFa'].str.replace(\" \",\"\")\n",
    "df['EducationMo'] = df['EducationMo'].str.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a7d79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.EducationFa != 'N/A']\n",
    "df = df[df.EducationMo != 'N/A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3d48bb",
   "metadata": {},
   "source": [
    "**Group similar groups of education type from EducationFa & EducationMo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73a358b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data transformation for EducationFa and EducationMo attributes\n",
    "\n",
    "#EducationFa attributes\n",
    "df.loc[(df['EducationFa'] == 'DOCTOR(S3)') | (df['EducationFa'] == 'MASTER(S2)') | (df['EducationFa'] == 'SPECIALIST2(Sp.2)'), 'EducationFa'] = 'level1'\n",
    "\n",
    "df.loc[(df['EducationFa'] == 'Sarjana(S1)') | (df['EducationFa'] == 'SPECIALIST1(Sp.1)') | (df['EducationFa'] == 'DIPLOMA(D4)')  | (df['EducationFa'] == 'Diploma(D4)')|\n",
    "       (df['EducationFa'] == 'DIPLOMA(D3)') | (df['EducationFa'] == 'DIPLOMA(D2)')|(df['EducationFa'] == 'Diploma(D2)') | (df['EducationFa'] == 'Diploma(D1)'), 'EducationFa'] = 'level2'\n",
    "\n",
    "df.loc[(df['EducationFa'] == 'TidaktamatSD') | (df['EducationFa'] == 'TamatSD') | (df['EducationFa'] == 'TamatSMP')|\n",
    "             (df['EducationFa'] == 'HIGHSCHOOL(SMA)') | (df['EducationFa'] == 'TamatSLTA'), 'EducationFa'] = 'level3'     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "defa0208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EducationMo attributes\n",
    "df.loc[(df['EducationMo'] == 'DOCTOR(S3)') | (df['EducationMo'] == 'MASTER(S2)') | (df['EducationMo'] == 'SPECIALIST2(Sp.2)'), 'EducationMo'] = 'level1'\n",
    "\n",
    "df.loc[(df['EducationMo'] == 'Sarjana(S1)') | (df['EducationMo'] == 'SPECIALIST1(Sp.1)')| (df['EducationMo'] == 'DIPLOMA(D4)') | (df['EducationMo'] == 'Diploma(D4)') | (df['EducationMo'] == 'DIPLOMA(D3)') | (df['EducationMo'] == 'DIPLOMA(D2)')\n",
    "             |(df['EducationMo'] == 'Diploma(D2)') | (df['EducationMo'] == 'Diploma(D1)'), 'EducationMo'] = 'level2'\n",
    "\n",
    "df.loc[(df['EducationMo'] == 'TidaktamatSD') | (df['EducationMo'] == 'TamatSD') | (df['EducationMo'] == 'TamatSD')| (df['EducationMo'] == 'TamatSMP')|\n",
    "             (df['EducationMo'] == 'HIGHSCHOOL(SMA)') | (df['EducationMo'] == 'TamatSLTA'), 'EducationMo']= 'level3'\n",
    "\n",
    "#finalDF[['EducationMo']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a81b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ScholarshipStatus'] = df['ScholarshipStatus'].str.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf0cd7d",
   "metadata": {},
   "source": [
    "**Group similar scholarship types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36c1b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['ScholarshipStatus'] == 'BINUSIAN') | (df['ScholarshipStatus'] == 'BeasiswaKaryawan')\n",
    "               | (df['ScholarshipStatus'] == 'SIBLINGSCHOLARSHIP')| (df['ScholarshipStatus'] == 'SiblingScholarship')\n",
    "               | (df['ScholarshipStatus'] == 'BeasiswaAnakKaryawan') | (df['ScholarshipStatus'] == 'BINUSIANCOMMUNITYSCHOLARSHIP')\n",
    "               | (df['ScholarshipStatus'] == 'BeasiswaBINUSAmbassador')\n",
    "                | (df['ScholarshipStatus'] == 'School:BinusianCommunityandEarlyBird')\n",
    "                | (df['ScholarshipStatus'] == 'School:BinusianCommunityorEarlyBird'), 'ScholarshipStatus'] = 'binusian'\n",
    "\n",
    "df.loc[ (df['ScholarshipStatus'] == 'TalentDevelopmentProgram')|\n",
    "             (df['ScholarshipStatus'] == 'NationDevelopmentProgram') | (df['ScholarshipStatus'] == 'BeasiswaBINUSINTERNATIONALSCHOOL') |                                                   \n",
    "             (df['ScholarshipStatus'] == 'DirectAdmissionBINUSINTERNATIONALSCHOOL') | (df['ScholarshipStatus'] == 'KerjasamaASAK') |                                                     \n",
    "            (df['ScholarshipStatus'] == 'BeasiswaAnakGuru') |(df['ScholarshipStatus'] == 'BeasiswaKerjasamaBINUS-AyoKuliah')\n",
    "             |(df['ScholarshipStatus'] == 'BEASISWAJURUSAN') |(df['ScholarshipStatus'] == 'BeasiswaJurusan')                                                \n",
    "             |(df['ScholarshipStatus'] == 'BeasiswaJuaraKompas-BINUS')|(df['ScholarshipStatus'] == 'BeasiswaKhususEducationExpo')\n",
    "            |(df['ScholarshipStatus'] == 'BeasiswaTalentMapping')|(df['ScholarshipStatus'] == 'Beasiswa')\n",
    "            |(df['ScholarshipStatus'] == 'BeasiswaUndanganSekolahKhusus')|(df['ScholarshipStatus'] == 'BeasiswaTPKS') | (df['ScholarshipStatus'] == 'BEASISWATPKSKHUSUS')\n",
    "            | (df['ScholarshipStatus'] == 'BeasiswaTPKSKhusus(NonRefundable)') |(df['ScholarshipStatus'] == 'BeasiswaBIDIKMISI')\n",
    "            | (df['ScholarshipStatus'] == 'WidiaPartialScholarship')|(df['ScholarshipStatus'] == 'widia')\n",
    "             | (df['ScholarshipStatus'] == 'WidiaScholarshipforOutstandingAchievers'), 'ScholarshipStatus'] = 'Other'\n",
    "\n",
    "df.loc[(df['ScholarshipStatus'] == 'PendaftaranBiasa') | (df['ScholarshipStatus'] == 'PendaftaranBiasa(EarlyBatch)')|\n",
    "        (df['ScholarshipStatus'] == 'School:Regular')|(df['ScholarshipStatus'] == 'Kalbis(TeknikInformatikadanMatematika2018)'), 'ScholarshipStatus'] = 'regular'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d5fb5b",
   "metadata": {},
   "source": [
    "### Grouping similar father's & Mother's jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ee2e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['FaJob'] == 'ABRI') | (df['FaJob'] == 'Guru')| (df['FaJob'] == 'Lain - Lain')\n",
    "             | (df['FaJob'] == 'PTN (Perguruan Tinggi Negeri)') | (df['FaJob'] == 'Wiraswasta') \n",
    "       | (df['FaJob'] == 'PTS (Perguruan Tinggi Swasta)'), 'FaJob'] = 'Other'\n",
    "                                                                           \n",
    "df.loc[(df['FaJob'] == 'Pensiun') | (df['FaJob'] == 'Tidak bekerja'), 'FaJob'] = 'Unemployement'\n",
    "df.loc[(df['FaJob'] == 'Pegawai negeri sipil') | (df['FaJob'] == 'Pegawai swasta'), 'FaJob'] = 'Employee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "279e2f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['MoJob'] == 'ABRI') | (df['MoJob'] == 'Guru')| (df['MoJob'] == 'Lain - Lain')| (df['MoJob'] == 'Petani')\n",
    "             | (df['MoJob'] == 'PTN (Perguruan Tinggi Negeri)') | (df['MoJob'] == 'Wiraswasta') \n",
    "       | (df['MoJob'] == 'PTS (Perguruan Tinggi Swasta)'), 'MoJob'] = 'Other'\n",
    "                                                                           \n",
    "df.loc[(df['MoJob'] == 'Pensiun') | (df['MoJob'] == 'Tidak bekerja'), 'MoJob'] = 'Unemployement'\n",
    "df.loc[(df['MoJob'] == 'Pegawai negeri sipil') | (df['MoJob'] == 'Pegawai swasta'), 'MoJob'] = 'Employee'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5981081",
   "metadata": {},
   "source": [
    "## IMPUTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df05b6b",
   "metadata": {},
   "source": [
    "**Imputation is applied on categorical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd29de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalDF.mode()['ScholarshipStatus'][0]\n",
    "mode = df.mode(axis=0, numeric_only = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82d4adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##imputation categorical values\n",
    "cols = ['ScholarshipStatus','EnglishScore', 'FaJob', 'MoJob', 'EducationFa',\n",
    "       'EducationMo', 'StatusFa', 'StatusMo', 'IntOrg', 'ExtOrg',\n",
    "       'PartInAcadComp', 'PartInNonacadCom',]\n",
    "df[cols]=df[cols].fillna(df.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "476272dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Gender != 'Unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ea87fe",
   "metadata": {},
   "source": [
    "### Remove unimportant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be8cb522",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(['NIM','Term', 'Status_x'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "085a5503",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'Status_y':'Status'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8778bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Angkatan','IPKTerakhir', 'SKSKumulatifTerakhir'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431cb2fc",
   "metadata": {},
   "source": [
    "## DUMMY VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac30be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars=['Gender', 'ScholarshipStatus', 'EnglishScore', 'FaJob', 'MoJob',\n",
    "       'EducationFa', 'EducationMo', 'StatusFa', 'StatusMo', 'IntOrg',\n",
    "       'ExtOrg', 'PartInAcadComp', 'PartInNonacadCom', 'JurusanOrProgram',\n",
    "       'KategoriJurusan', 'LokasiKuliah', 'Status', 'CekIPK','CekSKS']\n",
    "for var in cat_vars:\n",
    "    cat_list='var'+'_'+var\n",
    "    cat_list = pd.get_dummies(data[var], prefix=var)\n",
    "    data1=data.join(cat_list)\n",
    "    data=data1\n",
    "cat_vars=['Gender', 'ScholarshipStatus', 'EnglishScore', 'FaJob', 'MoJob',\n",
    "       'EducationFa', 'EducationMo', 'StatusFa', 'StatusMo', 'IntOrg',\n",
    "       'ExtOrg', 'PartInAcadComp', 'PartInNonacadCom', 'JurusanOrProgram',\n",
    "       'KategoriJurusan', 'LokasiKuliah', 'Status', 'CekIPK','CekSKS']\n",
    "data_vars=data.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i not in cat_vars]\n",
    "\n",
    "data_final=data[to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c919cde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NOVIYA~1.SAG\\AppData\\Local\\Temp/ipykernel_25288/4056789780.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_final.rename(columns={'Gender_Laki-Laki': 'Gender_Male', 'Gender_Perempuan': 'Gender_Female', 'StatusMo_Masih Hidup': 'StatusMo_alive', 'StatusMo_Telah Meninggal': 'StatusMo_died', 'LokasiKuliah_Alam Sutera' : 'LokasiKuliah_AlamSutera'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_final.rename(columns={'Gender_Laki-Laki': 'Gender_Male', 'Gender_Perempuan': 'Gender_Female', 'StatusMo_Masih Hidup': 'StatusMo_alive', 'StatusMo_Telah Meninggal': 'StatusMo_died', 'LokasiKuliah_Alam Sutera' : 'LokasiKuliah_AlamSutera'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8768cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.to_excel('finaldataset.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205690d5",
   "metadata": {},
   "source": [
    "### Setting the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1df8b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traindata\n",
    "X = data_final \n",
    "train = X.loc[(X['SemesterKe'] == 1) & (X['SemesterKe'] <= 4) ]\n",
    "test = X.loc[X['SemesterKe'] == 5]\n",
    "train = train.drop(['SemesterKe'], axis = 1)\n",
    "test = test.drop(['SemesterKe'], axis = 1)\n",
    "test = test.sample(n = 230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3cd17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = list(train) # Creates list of all column headers\n",
    "train[all_columns] = train[all_columns].astype('int64')\n",
    "\n",
    "all_columns = list(test) # Creates list of all column headers\n",
    "test[all_columns] = test[all_columns].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32593160",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_excel('train.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d69ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train set\n",
    "X_train = train.loc[:,train.columns != 'Evaluasi']\n",
    "y_train = train.loc[:, train.columns == 'Evaluasi']\n",
    "#test set\n",
    "X_test = test.loc[:,test.columns != 'Evaluasi']\n",
    "y_test = test.loc[:, test.columns == 'Evaluasi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a1aa66",
   "metadata": {},
   "source": [
    "### BALANCING WITH SMOTE (Trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "317c8cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling training data\n",
    "smote = SMOTE(random_state = 42)\n",
    "X, y = smote.fit_resample(X_train, y_train)\n",
    "#Oversampling testing data\n",
    "X1, y1 = smote.fit_resample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8fec0",
   "metadata": {},
   "source": [
    "#### Implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a09c608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.378325\n",
      "         Iterations 10\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               Evaluasi   No. Observations:                 1830\n",
      "Model:                          Logit   Df Residuals:                     1807\n",
      "Method:                           MLE   Df Model:                           22\n",
      "Date:                Mon, 05 Sep 2022   Pseudo R-squ.:                  0.4542\n",
      "Time:                        15:20:37   Log-Likelihood:                -692.33\n",
      "converged:                       True   LL-Null:                       -1268.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.003e-230\n",
      "==============================================================================================\n",
      "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Gender_Male                   -2.9316      1.072     -2.735      0.006      -5.033      -0.830\n",
      "Gender_Female                 -3.5294      1.091     -3.235      0.001      -5.668      -1.391\n",
      "ScholarshipStatus_Other       -3.8099      0.748     -5.091      0.000      -5.277      -2.343\n",
      "ScholarshipStatus_binusian    -3.8471      0.792     -4.859      0.000      -5.399      -2.295\n",
      "ScholarshipStatus_regular     -2.9961      0.750     -3.996      0.000      -4.466      -1.527\n",
      "EnglishScore_Advance          -4.9939      0.739     -6.757      0.000      -6.442      -3.545\n",
      "EnglishScore_Beginner         -3.2817      0.740     -4.433      0.000      -4.733      -1.831\n",
      "EnglishScore_Intermediate     -4.1549      0.731     -5.681      0.000      -5.588      -2.722\n",
      "FaJob_Employee                -4.4229      1.028     -4.304      0.000      -6.437      -2.409\n",
      "FaJob_Other                   -4.7107      1.026     -4.593      0.000      -6.721      -2.700\n",
      "FaJob_Unemployement           -4.6753      1.068     -4.379      0.000      -6.768      -2.583\n",
      "MoJob_Employee                -3.4453      0.752     -4.583      0.000      -4.919      -1.972\n",
      "MoJob_Other                   -4.0140      0.747     -5.373      0.000      -5.478      -2.550\n",
      "MoJob_Unemployement           -3.5097      0.740     -4.746      0.000      -4.959      -2.060\n",
      "EducationFa_level1            -4.0430      1.042     -3.881      0.000      -6.085      -2.001\n",
      "EducationFa_level2            -4.7052      1.026     -4.586      0.000      -6.716      -2.694\n",
      "EducationFa_level3            -5.0214      1.031     -4.871      0.000      -7.042      -3.001\n",
      "EducationMo_level1            -4.1139      0.849     -4.844      0.000      -5.779      -2.449\n",
      "EducationMo_level2            -3.5833      0.749     -4.783      0.000      -5.052      -2.115\n",
      "EducationMo_level3            -3.4003      0.747     -4.551      0.000      -4.865      -1.936\n",
      "StatusMo_alive                29.3020      2.455     11.938      0.000      24.491      34.113\n",
      "LokasiKuliah_AlamSutera       -3.1770      0.761     -4.173      0.000      -4.669      -1.685\n",
      "LokasiKuliah_Kemanggisan      -3.0522      0.753     -4.052      0.000      -4.529      -1.576\n",
      "==============================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X.loc[:, ['Gender_Male', 'Gender_Female', 'ScholarshipStatus_Other',\n",
    "       'ScholarshipStatus_binusian', 'ScholarshipStatus_regular',\n",
    "       'EnglishScore_Advance', 'EnglishScore_Beginner',\n",
    "       'EnglishScore_Intermediate', 'FaJob_Employee', 'FaJob_Other',\n",
    "       'FaJob_Unemployement', 'MoJob_Employee', 'MoJob_Other',\n",
    "       'MoJob_Unemployement', 'EducationFa_level1', 'EducationFa_level2',\n",
    "       'EducationFa_level3', 'EducationMo_level1', 'EducationMo_level2',\n",
    "       'EducationMo_level3',  'StatusMo_alive','LokasiKuliah_AlamSutera',\n",
    "       'LokasiKuliah_Kemanggisan']])\n",
    "result=logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec61dab",
   "metadata": {},
   "source": [
    "####  Logistic Regression Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f8b4372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noviyanti.sagala\\Anaconda3\\envs\\Research\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "var = ['Gender_Male', 'Gender_Female', 'ScholarshipStatus_Other',\n",
    "       'ScholarshipStatus_binusian', 'ScholarshipStatus_regular',\n",
    "       'EnglishScore_Advance', 'EnglishScore_Beginner',\n",
    "       'EnglishScore_Intermediate', 'FaJob_Employee', 'FaJob_Other',\n",
    "       'FaJob_Unemployement', 'MoJob_Employee', 'MoJob_Other',\n",
    "       'MoJob_Unemployement', 'EducationFa_level1', 'EducationFa_level2',\n",
    "       'EducationFa_level3', 'EducationMo_level1', 'EducationMo_level2',\n",
    "       'EducationMo_level3',  'StatusMo_alive','LokasiKuliah_AlamSutera',\n",
    "       'LokasiKuliah_Kemanggisan']\n",
    "X = X[var]\n",
    "X1 = X1[var]\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d4738e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X1)\n",
    "#print(classification_report(y1,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f19752fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9952ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a Pickle file using serialization \n",
    "import pickle\n",
    "pickle_out = open(\"modelLogR.pkl\",\"wb\")\n",
    "pickle.dump(logreg, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ff3c0",
   "metadata": {},
   "source": [
    "### **Results of Data Analysis :  ** \n",
    "   \n",
    "1. There are lots of missing and duplicated values from the raw data, especially student dataset given by IT Unit   \n",
    "2. Several attributes are considered as unimportant features, so they are removed.   \n",
    "3. Here are the statistical results (mode: the most common value in each feature)   \n",
    "Status                           Aktif   \n",
    "Gender                       Laki-Laki   \n",
    "ScholarshipStatus    Pendaftaran Biasa   \n",
    "EnglishScore                   Advance (PBT Score > 550)   \n",
    "FaJob                       Wiraswasta   \n",
    "MoJob                    Tidak bekerja    \n",
    "EducationFa                     level5 (Tidak tamat SD, tamat SD, tamat SMP, SMA, dan tamat SLTA)    \n",
    "EducationMo                     level5 (Tidak tamat SD, tamat SD, tamat SMP, SMA, dan tamat SLTA)     \n",
    "StatusFa                   Masih Hidup    \n",
    "StatusMo                   Masih Hidup      \n",
    "IntOrg                               N (Tidak mengikuti organisasi yang ada di BINUS)    \n",
    "ExtOrg                               N (Tidak mengikuti organisasi yang ada di luar BINUS)    \n",
    "PartInAcadComp                       N (TIdak pernah berpartisipasi dalam kompetisi akademik)     \n",
    "PartInNonacadCom                     N ( Tidak pernah berpartisipasi dalam kompetisi non-akademik)    \n",
    "JurusanOrProgram                   CSP (Computer Science Program)    \n",
    "KategoriJurusan                Reguler    \n",
    "LokasiKuliah               Kemanggisan    \n",
    "StatusKuliah                     Aktif    \n",
    "StatusIPK                           OK (> 2.00)    \n",
    "StatusSKS                           OK (Tidak kurang dari kelipatan 15 SKS)     \n",
    "Evaluasi                             0     \n",
    "\n",
    "4. Total number of students: 28066    \n",
    "Number of students who passed: 24474    \n",
    "Number of students who failed: 3592   \n",
    "SP3 rate of the class: 12.80%    \n",
    "\n",
    "5. The number of Non-NR observations are higher than NR.    \n",
    "   \n",
    "6. IPK Status= Kurang (IPK < 2.00) is the most influential factor to the rate of NR students. followed by SKS Status ( the cumulative of credits is less than multiple of 15 in each term).   \n",
    "    \n",
    "7. It is interesting to note that, Father Status (died/lived) is the third highest factor influencing student NR rate. Then, the campus location (kemanggisan/alam sutera) contribute a small amount the NR Rate.   \n",
    "    \n",
    "8. Overall, for the last 10 years, Computer Science Program is the program with the highest number of NR students, followed by Cyber Security Program. It is interesting to note that, Mobile Application & Tech (MAT) Program and Game Application Program(GAT) contributed at similar level to the number of NR students.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
